{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "from torch.autograd import grad\n",
    "from torch import nn\n",
    "import random\n",
    "os.chdir(os.path.split(os.getcwd())[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "torch.Size([1000, 3])\n",
      "torch.Size([1000, 1000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaoid\\AppData\\Local\\Temp\\ipykernel_10832\\665812767.py:10: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n",
      "  solutionValue = torch.tensor(f[\"solutionValues\"]).T\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(\".\\\\dataset\\\\unitData.h5\", 'r') as f:\n",
    "  d = list(f[\"solEvalPoints\"])\n",
    "  # IDs of nodes used as trunk network inputs\n",
    "  nodeID = list(map(int, d[0]))\n",
    "  # [x y t] of y points (trunk inputs).\n",
    "  # matrix with rows [x y t]\n",
    "  solEvalPoint = torch.tensor(np.concatenate([d[1][:, None], d[2][:, None], d[3][:, None]], axis = 1))\n",
    "  # DeepONet output targets (G(u)(y)) for all initial conditions\n",
    "  # matrix with 'initial condition' rows and 'y point' columns\n",
    "  solutionValue = torch.tensor(f[\"solutionValues\"]).T\n",
    "del d\n",
    "print(len(nodeID))\n",
    "print(solEvalPoint.shape)\n",
    "print(solutionValue.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 1000000 samples.\n"
     ]
    }
   ],
   "source": [
    "# number of sensors is equal to number of cases\n",
    "nCase = solutionValue.shape[0]\n",
    "nSensor = solutionValue.shape[0]\n",
    "# value of concentrated load as initial condition\n",
    "load = torch.tensor(-1.21 * 0.02).to(torch.float32)\n",
    "evalAmount = solEvalPoint.shape[0] # number of y points (trunk inputs)\n",
    "nSample = torch.numel(solutionValue) # amount of samples in dataset\n",
    "print(f\"Dataset contains {nSample} samples.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class acoustDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Dataset subclass to organize data\"\"\"\n",
    "    def __init__(self, evalPoint: torch.tensor, solVal: torch.tensor) -> None:\n",
    "        super(acoustDataset, self).__init__()\n",
    "        self.trunkInput = evalPoint\n",
    "        # target for model output\n",
    "        self.target = torch.flatten(solVal)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Overwrite method to fetch sample\"\"\"\n",
    "        # branch input load value at specific sensor. 0 everywhere else\n",
    "        branchInput = torch.zeros(nSensor, dtype = torch.float32)\n",
    "        branchInput[idx - (idx // nCase) * nCase] = load\n",
    "        branchInput.requires_grad_(True)\n",
    "        # index to access tensor with coordinates of evaluation point (trunk inputs)\n",
    "        i = idx - (idx // evalAmount) * evalAmount\n",
    "        trunkIn = [self.trunkInput[i, s].unsqueeze(0).requires_grad_(True) for s in range(3)]\n",
    "        # sample has (case evaluation at sensors, x, y, t, G(u)(y))\n",
    "        return branchInput, *trunkIn, self.target[idx].unsqueeze(0).requires_grad_(True)\n",
    "        # return (branchInput, self.trunkInput[i, 0].unsqueeze(0), self.trunkInput[i, 1].unsqueeze(0), self.trunkInput[i, 2].unsqueeze(0), self.target[idx].unsqueeze(0))\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Overwrite method to return size of dataset\"\"\"\n",
    "        return torch.numel(self.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shapes:\n",
      "  branch network inputs: torch.Size([64, 1000])\n",
      "  trunk network inputs:\n",
      "    x torch.Size([64, 1])\n",
      "    y torch.Size([64, 1])\n",
      "    t torch.Size([64, 1])\n",
      "  model output targets: torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "dataloader = torch.utils.data.DataLoader(acoustDataset(solEvalPoint, solutionValue),\n",
    "    batch_size = 64, shuffle = True, num_workers = 0\n",
    ")\n",
    "branchBatch, xBatch, yBatch, tBatch, targetBatch = next(iter(dataloader))\n",
    "print(f\"\"\"Batch shapes:\n",
    "  branch network inputs: {branchBatch.shape}\n",
    "  trunk network inputs:\n",
    "    x {xBatch.shape}\n",
    "    y {yBatch.shape}\n",
    "    t {tBatch.shape}\n",
    "  model output targets: {targetBatch.shape}\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "branchDepth = 7 # number of layers in branch network (MLP architecture)\n",
    "branchWidth = 100 # number of neurons in layers of branch network (MLP architecture)\n",
    "trunkDepth = 7 # number of layers in trunk network (MLP architecture)\n",
    "trunkWidth = 100 # number of neurons in layers of trunk network (MLP architecture)\n",
    "networkOutputDim = 100 # dimension of outputs of networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch - batched input torch.Size([64, 1000]) -> output: torch.Size([64, 100]).\n",
      "Trunk - batched input (torch.Size([64, 1]), torch.Size([64, 1]), torch.Size([64, 1])) -> output: torch.Size([64, 100]).\n",
      "Batch PI-DeepONet output shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "class branchNet(nn.Module):\n",
    "    \"\"\"Branch network definition\"\"\"\n",
    "    def __init__(self, inDim: int, nnDepth: int, nnWidth: int):\n",
    "        super().__init__()\n",
    "        # Input layer. Resizes input to desired network width\n",
    "        self.inputLayer = nn.Linear(inDim, nnWidth)\n",
    "        # intermediate dense layers. constant dimension\n",
    "        self.MLPstack = nn.ModuleList([nn.Linear(nnWidth, nnWidth) for _ in range(nnDepth - 2)])\n",
    "        # output layer. resizes network intermediate representation to networkOutputDim\n",
    "        self.outputLayer = nn.Linear(nnWidth, networkOutputDim)\n",
    "\n",
    "    def forward(self, x): # forward pass\n",
    "        x = self.inputLayer(x)\n",
    "        for l in self.MLPstack:\n",
    "            x = l(x)\n",
    "        return self.outputLayer(x)\n",
    "    \n",
    "class trunkNet(nn.Module):\n",
    "    \"\"\"Trunk network definition\"\"\"\n",
    "    def __init__(self, nnDepth: int, nnWidth: int):\n",
    "        super().__init__()\n",
    "        # Input layer. Resizes input to desired network width.\n",
    "        # consider trunk network as receiving individual inputs\n",
    "        # for each dimension (x, y, t)\n",
    "        self.xCoord = nn.Linear(1, nnWidth)\n",
    "        self.yCoord = nn.Linear(1, nnWidth)\n",
    "        self.tCoord = nn.Linear(1, nnWidth)\n",
    "        # intermediate dense layers. constant dimension\n",
    "        self.MLPstack = nn.ModuleList([nn.Linear(nnWidth, nnWidth) for _ in range(nnDepth - 2)])\n",
    "        # output layer. resizes network intermediate representation to networkOutputDim\n",
    "        self.outputLayer = nn.Linear(nnWidth, networkOutputDim)\n",
    "\n",
    "    def forward(self, x, y, t): # forward pass\n",
    "        x = self.xCoord(x)\n",
    "        y = self.yCoord(y)\n",
    "        t = self.tCoord(t)\n",
    "        o = x + y + t\n",
    "        for l in self.MLPstack:\n",
    "            o = l(o)\n",
    "        return self.outputLayer(o)\n",
    "    \n",
    "# Branch network. Embeds evaluations of the input functions 'u' at sensors\n",
    "branchNetwork = branchNet(nSensor, branchDepth, branchWidth)\n",
    "branchOut = branchNetwork(branchBatch)\n",
    "# Trunk network. Embeds spatiotemporal coordinates (x, y, t) of\n",
    "# point y, in which the PDE solution (G(u)(y)) is evaluated\n",
    "trunkNetwork = trunkNet(trunkDepth, trunkWidth)\n",
    "trunkOut = trunkNetwork(xBatch, yBatch, tBatch)\n",
    "# Shapes of outputs of networks\n",
    "print(f\"\"\"Branch - batched input {branchBatch.shape} -> output: {branchOut.shape}.\n",
    "Trunk - batched input ({xBatch.shape}, {yBatch.shape}, {tBatch.shape}) -> output: {trunkOut.shape}.\"\"\")\n",
    "\n",
    "class PI_deepONet(nn.Module):\n",
    "    \"\"\"Class for physics-informed DeepONet\"\"\"\n",
    "    def __init__(self, branch: nn.Module, trunk: nn.Module):\n",
    "        super().__init__()\n",
    "        self.branch = branch\n",
    "        self.trunk = trunk\n",
    "\n",
    "    def forward(self, case: torch.tensor, x: torch.tensor, y: torch.tensor, t: torch.tensor):\n",
    "        # transpose trunk output and multiply both for\n",
    "        # sample-by-sample dot product in diagonal of result\n",
    "        return torch.diagonal(torch.matmul(self.branch(case), self.trunk(x, y, t).T))\n",
    "    \n",
    "model = PI_deepONet(branchNetwork, trunkNetwork)\n",
    "modelOut = model(branchBatch, xBatch, yBatch, tBatch)\n",
    "print(f\"Batch PI-DeepONet output shape: {modelOut.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PINN loss term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outM = model(branchBatch, xBatch, yBatch, tBatch)\n",
    "# p_x = grad(outM.sum(), xBatch, create_graph = True)[0]\n",
    "# p_xx = grad(p_x.sum(), xBatch)[0]\n",
    "# print(p_x.shape)\n",
    "# print(p_xx.shape)\n",
    "\n",
    "# def sf(bb, xb, yb, tb):\n",
    "#     return torch.sum(model(bb, xb, yb, tb))\n",
    "# torch.autograd.functional.hessian(sf, (branchBatch, xBatch, yBatch, tBatch), create_graph = False, strict = False)\n",
    "\n",
    "def PDEresidual(case: torch.tensor, evalPoint: torch.tensor, m: torch.Module) -> torch.tensor:\n",
    "    \"\"\"PDE residual through AD for physics-informed loss term\"\"\"\n",
    "    p = model(case, evalPoint)\n",
    "    p_x = torch.autograd.grad(p, , create_graph=True)[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acousticPINNs-v9ZJkn9d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
